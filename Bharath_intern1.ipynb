{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJN/pFDe47ClFVSUvFWbF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inthiyaz63/inthiyaz63/blob/main/Bharath_intern1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stock prediction**"
      ],
      "metadata": {
        "id": "RZs7ktgczW4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the impartant libraries"
      ],
      "metadata": {
        "id": "KpbCa5q6zYEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vbfBny5WzHkK"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost\n",
        "import lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For reading stock data from yahoo\n",
        "from pandas_datareader.data import DataReader\n",
        "# For time stamps\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "3-QWpDGD3kvI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the first dataset\n",
        "columns=['Date','Category','News']\n",
        "ndf = pd.read_csv(\"india-news-headlines.csv\",names=columns)"
      ],
      "metadata": {
        "id": "F0-saRwm3k2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "0c8c89e4-10d4-437c-893e-c0a39a93dfcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6b7b993e8cab>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the first dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'News'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"india-news-headlines.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'india-news-headlines.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Showing part of the whole dataset:')\n",
        "ndf.head(5)"
      ],
      "metadata": {
        "id": "bx463_cD3k6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndf.drop(0, inplace=True)\n",
        "ndf.drop('Category', axis = 1, inplace=True)\n",
        "print('Showing part of the whole dataset:')\n",
        "ndf.head(-5)"
      ],
      "metadata": {
        "id": "nXg8uGED3k_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the second dataset\n",
        "hisdf = pd.read_csv(\"^BSESN.csv\")\n",
        "hisdf.head(-5)"
      ],
      "metadata": {
        "id": "dIpjoCck3lD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for common information of the first datast\n",
        "ndf[\"Date\"] = pd.to_datetime(ndf[\"Date\"],format='%Y%m%d')\n",
        "ndf.info()"
      ],
      "metadata": {
        "id": "2VgIfCI23lHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the headlines for each day\n",
        "ndf['News'] = ndf.groupby(['Date']).transform(lambda x : ' '.join(x))\n",
        "ndf = ndf.drop_duplicates()\n",
        "ndf.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "G3WrR_lt3lMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndf"
      ],
      "metadata": {
        "id": "OG8JJUMT3lWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any duplicated values\n",
        "ndf.isnull().sum()"
      ],
      "metadata": {
        "id": "wUGY-nKk3lak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ndf)"
      ],
      "metadata": {
        "id": "TaD743u03lp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hisdf=hisdf[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
        "hisdf.head(-5)"
      ],
      "metadata": {
        "id": "Zk3yXlXG3luz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hisdf.describe()"
      ],
      "metadata": {
        "id": "fFWWfPbd3l0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicated values\n",
        "hisdf.isnull().sum()"
      ],
      "metadata": {
        "id": "iB5zWAbj3l5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(hisdf)"
      ],
      "metadata": {
        "id": "oVa05Rqn3mKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure plot\n",
        "plt.figure(figsize=(20,10))\n",
        "hisdf['Close'].plot()\n",
        "plt.ylabel('BSESN')"
      ],
      "metadata": {
        "id": "dpzrC32Z3mRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing unwanted characters from the News\n",
        "ndf.replace(\"[^a-zA-Z']\",\" \",regex=True,inplace=True)\n",
        "ndf[\"News\"].head(5)"
      ],
      "metadata": {
        "id": "Z6a8Zhod3mWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting moving average\n",
        "close = hisdf['Close']\n",
        "\n",
        "ma = close.rolling(window = 50).mean()\n",
        "std = close.rolling(window = 50).std()\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "hisdf['Close'].plot(color='g',label='Close')\n",
        "ma.plot(color = 'r',label='Rolling Mean')\n",
        "std.plot(label = 'Rolling Standard Deviation')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "vpD3U3Rd3mbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting returns\n",
        "returns = close / close.shift(1) - 1\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "returns.plot(label='Return', color = 'g')\n",
        "plt.title(\"Returns\")"
      ],
      "metadata": {
        "id": "SZvtKmFU3mgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "train = hisdf[:1219]\n",
        "test = hisdf[1219:]"
      ],
      "metadata": {
        "id": "SkD0D3bY3mmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stationarity test\n",
        "def test_stationarity(timeseries):\n",
        "\n",
        " #Determine the rolling statistics\n",
        " rolmean = timeseries.rolling(20).mean()\n",
        " rolstd = timeseries.rolling(20).std()\n",
        "\n",
        " #Plot rolling statistics:\n",
        " plt.figure(figsize = (20,10))\n",
        " plt.plot(timeseries, color = 'blue', label = 'original')\n",
        " plt.plot(rolmean, color = 'r', label = 'rolling mean')\n",
        " plt.plot(rolstd, color = 'black', label = 'rolling std')\n",
        " plt.xlabel('Date')\n",
        " plt.legend()\n",
        " plt.title('Rolling Mean and Standard Deviation',  fontsize = 30)\n",
        " plt.show(block = False)\n",
        "\n",
        " print('Results of dickey fuller test')\n",
        " result = adfuller(timeseries, autolag = 'AIC')\n",
        " labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        " for value,label in zip(result, labels):\n",
        "   print(label+' : '+str(value) )\n",
        " if result[1] <= 0.05:\n",
        "   print(\"Strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n",
        " else:\n",
        "   print(\"Weak evidence against null hypothesis, time series is non-stationary \")\n",
        "test_stationarity(train['Close'])"
      ],
      "metadata": {
        "id": "NtUygaDR3mvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_log = np.log(train['Close'])\n",
        "test_log = np.log(test['Close'])\n",
        "\n",
        "mav = train_log.rolling(24).mean()\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.plot(train_log)\n",
        "plt.plot(mav, color = 'red')"
      ],
      "metadata": {
        "id": "81M-Tzfl3m57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_log.dropna(inplace = True)\n",
        "test_log.dropna(inplace = True)\n",
        "\n",
        "test_stationarity(train_log)"
      ],
      "metadata": {
        "id": "hEqpquK_3nAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_log_diff = train_log - mav\n",
        "train_log_diff.dropna(inplace = True)\n",
        "\n",
        "test_stationarity(train_log_diff)"
      ],
      "metadata": {
        "id": "8QfcLc8D3nIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using auto arima to make predictions using log data\n",
        "from pmdarima import auto_arima"
      ],
      "metadata": {
        "id": "4fdpg2vM3nSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = auto_arima(train_log, trace = True, error_action = 'ignore', suppress_warnings = True)\n",
        "model.fit(train_log)\n",
        "predictions = model.predict(periods = len(test))\n",
        "predictions = pd.DataFrame(predictions,index = test_log.index,columns=['Prediction'])"
      ],
      "metadata": {
        "id": "dMpGD5is3nXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_log, label='Train')\n",
        "plt.plot(test_log, label='Test')\n",
        "plt.plot(predictions, label='Prediction')\n",
        "plt.title('BSESN Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Actual Stock Price')"
      ],
      "metadata": {
        "id": "vjw0qsP55NuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating error\n",
        "rms = np.sqrt(mean_squared_error(test_log,predictions))\n",
        "print(\"RMSE : \", rms)"
      ],
      "metadata": {
        "id": "xOTsKicl5Nz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to get the subjectivity and polarity\n",
        "def getSubjectivity(text):\n",
        "  return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "def getPolarity(text):\n",
        "  return  TextBlob(text).sentiment.polarity"
      ],
      "metadata": {
        "id": "wL2J1L2y5N5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding subjectivity and polarity columns\n",
        "ndf['Subjectivity'] = ndf['News'].apply(getSubjectivity)\n",
        "ndf['Polarity'] = ndf['News'].apply(getPolarity)\n",
        "ndf"
      ],
      "metadata": {
        "id": "qCU-jIgr5OEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding sentiment score to df_news\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "50k_NEqT5OJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndf['Compound'] = [sia.polarity_scores(v)['compound'] for v in ndf['News']]\n",
        "ndf['Negative'] = [sia.polarity_scores(v)['neg'] for v in ndf['News']]\n",
        "ndf['Neutral'] = [sia.polarity_scores(v)['neu'] for v in ndf['News']]\n",
        "ndf['Positive'] = [sia.polarity_scores(v)['pos'] for v in ndf['News']]\n",
        "ndf"
      ],
      "metadata": {
        "id": "0CwFnkE95ONH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge = pd.merge(hisdf, ndf, how='inner', on='Date')\n",
        "df_merge"
      ],
      "metadata": {
        "id": "z4YlVtzi5ORV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfmerge1 = df_merge[['Close','Subjectivity', 'Polarity', 'Compound', 'Negative', 'Neutral', 'Positive']]\n",
        "dfmerge1"
      ],
      "metadata": {
        "id": "hg-PLUSH5OU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "df = pd.DataFrame(scaler.fit_transform(dfmerge1))\n",
        "df.columns = dfmerge1.columns\n",
        "df.index = dfmerge1.index\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rsKumoLi5OYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop('Close',axis=1)\n",
        "X"
      ],
      "metadata": {
        "id": "VFw6dmLO5OcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=df['Close']\n",
        "Y"
      ],
      "metadata": {
        "id": "DqsOKHub5OfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "2Ifb8wrT5wwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:10]"
      ],
      "metadata": {
        "id": "t3nFj5v15w4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()\n",
        "rf.fit(x_train, y_train)\n",
        "prediction=rf.predict(x_test)"
      ],
      "metadata": {
        "id": "xL4xC5ek5w_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction[:10])\n",
        "print(y_test[:10])\n",
        "print('Mean Squared error: ',mean_squared_error(prediction,y_test))"
      ],
      "metadata": {
        "id": "iFQdIT4g5xF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtr = DecisionTreeRegressor()\n",
        "dtr.fit(x_train, y_train)\n",
        "predictions = dtr.predict(x_test)"
      ],
      "metadata": {
        "id": "KHfldlvZ5xNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions[:10])\n",
        "print(y_test[:10])\n",
        "print('Mean Squared error: ',mean_squared_error(predictions,y_test))"
      ],
      "metadata": {
        "id": "45xw_WMC5xW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adb = AdaBoostRegressor()\n",
        "adb.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "bZBEtwzA5xb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = adb.predict(x_test)\n",
        "print(mean_squared_error(predictions, y_test))"
      ],
      "metadata": {
        "id": "4mMv34du6Trs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm = lightgbm.LGBMRegressor()\n",
        "gbm.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Cgo-HuOM6T6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = gbm.predict(x_test)\n",
        "print(mean_squared_error(predictions, y_test))"
      ],
      "metadata": {
        "id": "ln5dqIOO6UCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = xgboost.XGBRegressor()\n",
        "xgb.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "uyAYjZzd6ULX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb.predict(x_test)\n",
        "print(mean_squared_error(predictions, y_test))"
      ],
      "metadata": {
        "id": "AbGg3tDJ6US3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End**"
      ],
      "metadata": {
        "id": "BdbSHn7WzV2m"
      }
    }
  ]
}